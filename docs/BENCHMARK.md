# E4S Index System - Benchmark Report

## Executive Summary

The E4S Index System demonstrates excellent performance characteristics for time-series data indexing:

- **In-Memory Performance**: 11-14 million operations per second
- **Redis Performance**: 1.9-3.2 million operations per second (with cache hits)
- **Memory Efficiency**: ~2 bytes per time entry
- **Scalability**: 1M meters with 1 year of data requires ~744 MB

---

## Test Configuration

### In-Memory Benchmark

| Parameter | Value |
|-----------|-------|
| Index Name | meter_pq_index |
| Meters | 100 |
| Days per Meter | 365 |
| Year | 2025 |
| Total Entries | 36,500 |
| Warmup Iterations | 3 |
| Measurement Iterations | 5 |
| Operations per Iteration | 100,000 |

### Redis Benchmark

| Parameter | Value |
|-----------|-------|
| Redis | 7-alpine, 256MB max memory |
| Index Name | meter_pq_index |
| Meters | 100 |
| Days per Meter | 365 |
| Year | 2025 |
| Total Entries | 36,500 |
| Cache Size | 200 entries |
| Warmup Iterations | 3 |
| Measurement Iterations | 5 |
| Operations per Iteration | 10,000 |

---

## Performance Results

### In-Memory Benchmark

| Operation | Throughput (ops/sec) |
|-----------|---------------------|
| existsDay | 14,002,269 |
| existsMonth | 13,841,421 |
| findPrevDay | 11,478,190 |
| findNextDay | 11,349,782 |
| findPrevMonth | 13,843,496 |
| findNextMonth | 13,405,485 |

### Redis Benchmark (with LRU Cache)

| Operation | Throughput (ops/sec) | Latency (Î¼s/op) |
|-----------|---------------------|-----------------|
| existsDay | 2,284,348 | 0.44 |
| existsMonth | 2,797,796 | 0.36 |
| findPrevDay | 1,913,634 | 0.52 |
| findNextDay | 2,824,553 | 0.35 |
| findPrevMonth | 2,718,930 | 0.37 |
| findNextMonth | 3,210,582 | 0.31 |

---

## Memory Usage

### Benchmark Data

| Metric | Value |
|--------|-------|
| Total Index Memory | 76.37 KB |
| Per Meter (Day) | 744 bytes |
| Per Meter (Month) | 38 bytes |
| Bytes per Entry | 2.14 |

### Memory Estimation by Scale

| Scale | Day Index (1 year) | Month Index (1 year) | Total Memory |
|-------|-------------------|---------------------|--------------|
| 100 meters | 74 KB | 4 KB | 78 KB |
| 1,000 meters | 744 KB | 38 KB | 782 KB |
| 10,000 meters | 7.4 MB | 380 KB | 7.8 MB |
| 100,000 meters | 74 MB | 3.8 MB | 78 MB |
| 1,000,000 meters | 744 MB | 38 MB | 782 MB |
| 10,000,000 meters | 7.4 GB | 380 MB | 7.8 GB |

---

## Performance Comparison

### In-Memory vs Redis

| Operation | In-Memory | Redis | Slowdown Factor |
|-----------|-----------|-------|-----------------|
| existsDay | 14.0M ops/sec | 2.3M ops/sec | 6.1x |
| existsMonth | 13.8M ops/sec | 2.8M ops/sec | 4.9x |
| findPrevDay | 11.5M ops/sec | 1.9M ops/sec | 6.0x |
| findNextDay | 11.3M ops/sec | 2.8M ops/sec | 4.0x |
| findPrevMonth | 13.8M ops/sec | 2.7M ops/sec | 5.1x |
| findNextMonth | 13.4M ops/sec | 3.2M ops/sec | 4.2x |

### Analysis

The Redis benchmark shows lower throughput due to:
1. Network latency between application and Redis
2. Serialization/deserialization overhead
3. Cache misses requiring Redis lookups

However, the LRU cache significantly mitigates this by caching frequently accessed data:
- Cache hit: In-memory speed (~14M ops/sec)
- Cache miss: Redis roundtrip (~0.5-1M ops/sec)

With a properly sized cache (100K+ entries), most queries will hit the cache, maintaining high throughput.

---

## Scalability Analysis

### Storage Efficiency

RoaringBitmap provides excellent compression for dense time-series data:

| Data Pattern | Storage per Entry |
|--------------|-------------------|
| Dense (>80% coverage) | ~2 bytes |
| Medium (30-70% coverage) | ~4 bytes |
| Sparse (<30% coverage) | ~8 bytes |

### Scaling Recommendations

| Scale | Recommended Configuration |
|-------|--------------------------|
| < 100K meters | Single instance, default cache |
| 100K - 1M meters | Single instance, 500K cache |
| 1M - 10M meters | Single instance, 1M cache, 8GB heap |
| > 10M meters | Consider sharding by meter ID |

---

## Benchmark Reproduction

### Prerequisites

- Docker installed
- Java 17+
- Maven 3.8+

### Run In-Memory Benchmark

```bash
mvn clean package -DskipTests
mvn exec:java@run-benchmark
```

### Run Redis Benchmark

```bash
./run-benchmark.sh
```

Or manually:

```bash
# Start Redis
docker run -d --name e4s-redis -p 6379:6379 redis:7-alpine

# Build
mvn clean package test-compile -DskipTests

# Run benchmark
REDIS_HOST=localhost REDIS_PORT=6379 mvn exec:java@run-benchmark

# Cleanup
docker stop e4s-redis && docker rm e4s-redis
```

### Run with Docker Compose

```bash
# Start services
docker-compose up -d

# Check logs
docker-compose logs -f index-service

# Stop
docker-compose down
```

---

## Conclusion

The E4S Index System delivers:

1. **High Throughput**: Millions of operations per second
2. **Low Latency**: Sub-microsecond for in-memory, sub-millisecond for cached Redis queries
3. **Memory Efficient**: ~2 bytes per entry with RoaringBitmap compression
4. **Scalable**: Supports millions of meters with modest hardware requirements

The system is well-suited for:
- Time-series data existence tracking
- Gap detection in data pipelines
- Fast navigation between data points
- Multi-tenant index management

---

*Report generated on: 2026-02-20*
*Benchmark environment: macOS, JDK 21, Redis 7*
